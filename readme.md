![Image](https://miro.medium.com/v2/resize:fit:1100/1*CniSdF4zewDrajSHwCekSQ.gif)
# Topics Covered

<details>
    <summary>I. Perceptron</summary>

  1. Perceptron
  2. Geometric Intuition

</details>

<details>
    <summary>II. Multi Layer Perceptron</summary>
    
  1. MLP Notation
  2. MLP Intuition
  3. MLP Example
  4. Change Architecture
  5. Change Architecture II
  6. MLP Forward Propagation
  7. MLP Forward Propagation II
  8. MLP Forward Propagation III
  9. MLP Forward Propagation IV
  10. MLP Backpropagation
  11. MLP Backpropagation II
  12. MLP Backpropagation III
  13. MLP Backpropagation (Classification)
  14. Backpropagation Intuition (Loss Function-Gradient)
  15. Backpropagation Intuition (Derivative-Minima)
  16. Backpropagation Intuition
  17. Effect of Learning Rate

</details>

<details>
    <summary>III. Improve Performance</summary>
    
  1. Loss Function
  2. Loss Function (MSE)
  3. Loss Function (MAE and Huber)
  4. Loss Function (Binary Cross Entropy)
  5. Loss Function (Categorical Cross Entropy)
  6. Memoization
  7. Gradient Descent I
  8. Gradient Descent II
  9. Vanishing Gradient Problem
  10. Solve Vanishing Gradient Problem
  11. Improve Neural Network
  12. Problem with Neural Network
  13. Early Stopping
  14. Normalizing Input
  15. Dropout Layer I
  16. Dropout Layer II
  17. Regularization
  18. Regularization Intuition
  19. Activation Function
  20. Activation Function (Sigmoid)
  21. Activation Function (Tanh)
  22. Activation Function (ReLu)
  23. Activation Function (Dying ReLu Problem)
  24. Activation Function (Relu Variation I)
  24. Activation Function (Relu Variation II)
  25. Weight Initialization Technique
  26. Weight Initialization (Zero Initialization I)
  27. Weight Initialization (Zero Initialization II)
  28. Weight Initialization (Non-Zero Constant)
  29. Weight Initialization (Random Initialization-small I)
  30. Weight Initialization (Random Initialization-small II)
  31. Weight Initialization (Random Initialization-large I)
  32. Weight Initialization (Random Initialization-large II)
  33. Weight Initialization
  34. Batch Normalization I
  35. Batch Normalization II
  36. Batch Normalization III
  36. Understanding Graph
  37. Exponantially Weighted Moving Average
  38. Exponantially Weighted Moving Average (Intuition)
  39. Optimizers
  40. Optimizers (Momentum)
  41. Optimizers (NAG)
  42. Optimizers (AdaGrad)
  43. Optimizers (AdaGrad Intuition)
  44. Optimizers (RMSProp)
  45. Optimizers (Adam)
  46. Functional API
  47. Functional API (Topology)
  48. Functional API (Topology II)

</details>

<details>
    <summary>IV. Convolutional Neural Network</summary>
    
  1. Convolution Operation I
  2. Convolution Operation II
  3. Padding
  4. Stride
  5. Pooling
  6. Pooling Code and Advantage
  7. Pooling Disadvantage
  8. CNN Architecture
  9. LeNet-5
  10. CNN vs ANN
  11. Backpropagation in CNN I
  12. Backpropagation in CNN II
  13. Backpropagation in CNN III
  14. Backpropagation in CNN IV
  15. Backpropagation in CNN V
  16. Pretrained Model in CNN
  17. Transfer Learning in CNN-Feature Extraction
  18. Feature Extraction Code
  19. Transfer Learning in CNN-Fine Tuning
  20. Fine Tuning Code

</details>

<details>
    <summary>V. Recurrent Neural Network</summary>
    
  1. RNN Introduction
  2. Data feeding in RNN
  3. RNN Intuition
  4. RNN Representation
  5. Types of RNN I
  6. Types of RNN II
  7. RNN Forward Propagation
  8. RNN Backpropagation I
  9. RNN Backpropagation II
  10. RNN Backpropagation III
  11. Problem with RNN I
  12. Problem with RNN II
     

</details>

<details>
    <summary>Research Papers</summary>

  1. (1957) Frank Rosenblatt - Perceptron
  2. (1959) Receptice Field Experimernt used in CNN
  3. (1969) Marvin Minsky - First AI winter
  4. (1980) Geoff Hinton - Learning representation using back propogation error
  5. (1981) Fukushima Miyake - Early CNN
  6. (1989) Yan LeCun - Handwritten Digit Recognition
  7. (2006) Geoff Hinton - Deep belief network
  8. (2012) Imagenet Classification with Deep CNN
  9. (2014) Dropout Discovery
  10. (2014) GAN Discovery
  11. (2016) Regularization for Deep Learning
 

</details>




### We appreciate your interest and contributions to the EnthuAi repository
